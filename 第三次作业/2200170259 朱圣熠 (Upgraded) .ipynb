{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37e135f5-b589-451f-87bb-1935633efdc5",
   "metadata": {},
   "source": [
    "# 暂时不考虑正则化，先直接莽一莽"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64170717-9dda-40f0-82be-512da2a29a13",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "## Cell 1: \n",
    "#### Standardization 函数，取得 data_mean 和 data_std_variance 只是偷懒用的添头，而且只用一次——无关紧要\n",
    "&nbsp;\n",
    "#### 顺便，我们先确定了loss函数的形式：\n",
    "&nbsp;\n",
    "# &emsp; loss($\\vec{\\omega}$) = ${ \\sum_{ i=0 } ^ { m } } \\frac{ ( y_{ i } - \\vec{ \\omega } · \\vec{ x }_{ i } )^2 }{ 2m }$\n",
    "&nbsp;\n",
    "#### 其中 m 表示所选数据集的样本总数，\n",
    "#### $\\vec{ \\omega }$ 是线性回归模型的待求参数，\n",
    "#### $y_{ i }$ 是第i个样本的待预测属性的真实值，\n",
    "#### $\\vec{ x }_{ i }$ 是第i个样本的特征组成的向量 (有一个分量的值固定为1)\n",
    "&nbsp;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3526ad1-75a0-4d5f-8cf1-298031180a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def Standardization(data_list):\n",
    "    data_mean = np.mean(data_list)\n",
    "    data_std_variance = np.std(data_list)\n",
    "    std_data_list = [(data - data_mean) / data_std_variance for data in data_list]\n",
    "    return std_data_list, data_mean, data_std_variance\n",
    "\n",
    "def Predict(vector_feature_list, vector_parameter):\n",
    "    return [np.dot(vector_parameter, vector_feature) for vector_feature in vector_feature_list]\n",
    "\n",
    "def Get_Loss(error_list):\n",
    "    return np.linalg.norm(error_list) ** 2 / 2.0 / len(error_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec89afa-a120-40f8-b716-7e47107e9b34",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "## Cell 2: \n",
    "#### 从绝对路径读取得到 source_data ( 类型: data frame )\n",
    "#### 我们选择 source_data 末尾的10个样本作为 Validation Set\n",
    "#### 并且通过输出预览 source_data 的基本情况\n",
    "&nbsp;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1047bc3-08a2-4185-b965-8ef868b22d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2\n",
    "\n",
    "source_data_abs_path = 'E:/Python Program File/regress_data2.csv'\n",
    "source_data = pd.read_csv(source_data_abs_path)\n",
    "\n",
    "line_num = source_data.shape[0]\n",
    "column_num = source_data.shape[1]\n",
    "validation_set_size = 10\n",
    "train_set_size = line_num - validation_set_size\n",
    "\n",
    "print(source_data.tail(validation_set_size))\n",
    "print(source_data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e89acc4-9c58-4055-bd67-4f021a150e02",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "![此处应当通过markdown语法插入本地图片，显示print方法的打印结果](./fig1.png)\n",
    "&nbsp;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e873be2-6851-439c-9f7c-0bf77258e6b5",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "## Cell 3\n",
    "#### 按照先前的划分方案，读取 source_data 中的 Train Set 部分\n",
    "#### Price <- Price / 1000 可以方便作图，但笔者不确定该步骤对后续求解 $\\vec{ \\omega }$ 的影响\n",
    "#### 作三维散点图，预览 标准化之前的样本 特征的基本情况\n",
    "&nbsp;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e707da-5ffd-4d52-9451-dbc85c64d3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3\n",
    "\n",
    "data_list_list = []\n",
    "for i in range(column_num):\n",
    "    data_list_list.append(source_data.iloc[:, i])\n",
    "\n",
    "area_list = data_list_list[0][0: train_set_size]\n",
    "room_num_list = data_list_list[1][0: train_set_size]\n",
    "price_list = data_list_list[2][0: train_set_size]\n",
    "price_list /= 1000\n",
    "\n",
    "figure = plt.figure()\n",
    "subplot = figure.add_subplot(projection='3d')\n",
    "subplot.plot(area_list, room_num_list, price_list,\n",
    "             marker='o', markersize=5,\n",
    "             markerfacecolor='brown', markeredgecolor='orange', linestyle='none')\n",
    "\n",
    "subplot.set_title('Preview of Train Sets')\n",
    "subplot.set_xlabel('Area', fontsize=10)\n",
    "subplot.set_ylabel('Room Number', fontsize=10)\n",
    "subplot.set_zlabel('(Price/1000)', fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a673be2f-5b8a-411b-b13c-87466ea390bc",
   "metadata": {},
   "source": [
    "![此处应当通过markdown语法插入本地图片，显示plot方法的绘制结果](./fig2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ceb152-638a-4ec0-be9d-48cc9cccbcff",
   "metadata": {},
   "source": [
    "## Cell 4:\n",
    "#### 对训练集中的数据进行标准化，\n",
    "#### 取得训练集各项数据的均值和标准差，\n",
    "#### 并且准备好用于求解 $\\vec{ \\omega }$ 的 $\\vec{ x }_{ i }$\n",
    "&nbsp;\n",
    "## 对于标准化处理后的训练集，之后就认为当中的元素服从标准正态分布了\n",
    "&nbsp;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56276bed-7e58-44b1-a264-c73acbe59e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4\n",
    "\n",
    "# Assumption: Gaussian Distributed\n",
    "\n",
    "std_area_list, area_mean, area_std_variance = Standardization(area_list)\n",
    "std_room_num_list, room_num_mean, room_num_std_variance = Standardization(room_num_list)\n",
    "\n",
    "feature_vector_list = []\n",
    "for i in range(train_set_size):\n",
    "    feature_vector_list.append([std_area_list[i], std_room_num_list[i], 1.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6741ff-3d8c-47c8-966b-f6f3e3c261e5",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "## Cell 5:\n",
    "## 这一步是 Batch Gradient Descent 的运用\n",
    "#### 初始化 loss_history_list 以便记录训练过程中loss函数值的变化\n",
    "#### 初始化 omega_list 以选择梯度下降方法的起点\n",
    "#### learning_rate 固定为0.2，不是最好的做法，但不妨试试。\n",
    "## 然后进入关键流程\n",
    "&nbsp;\n",
    "#### 先拜一拜初等微积分，请看下图:\n",
    "&nbsp;\n",
    "![此处应当通过markdown语法插入本地图片，显示关于全微分的知识](./theory1.jpg)\n",
    "&nbsp;\n",
    "#### 照猫画虎，研究一下loss函数，发现给定 $\\vec{ \\omega }$ 就可以求得具体的偏导数值:\n",
    "&nbsp;\n",
    "# &emsp;$\\frac{ \\partial loss }{ \\partial \\omega_{ i } } $($\\vec{ \\omega }$) = ${ \\sum_{ j=1 } ^ { m } }$ -$\\frac{ x_{ji} }{ m }$($y_{ j } - \\vec{ \\omega } · \\vec{ x }_{ j }$)\n",
    "&nbsp;\n",
    "#### 其中 $\\omega_{ i }$ 代表 $\\vec{ \\omega }$ 的第i个分量, $x_{ji}$ 代表 $\\vec{ x }_{ j }$ 的第i个分量\n",
    "&nbsp;\n",
    "#### 于是一系列偏导数值就构成了当次更新 omega_list 所需的 gradient_vector\n",
    "#### 因为是根据梯度\"下山\"，所以最后 omega_list -= gradient_array * learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de98c2e-ca7f-4d52-92ae-50e1d6bc5ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5\n",
    "\n",
    "# Q:How to give better initial guess\n",
    "\n",
    "loss_history_list = []\n",
    "omega_list = [0.0, 0.0, 0.0]\n",
    "learning_rate = 0.2\n",
    "\n",
    "# Q:How to upgrade learning rate\n",
    "\n",
    "for loop_count in range(100):\n",
    "\n",
    "    gradient_vector = [0.0, 0.0, 0.0]\n",
    "    prediction_list = Predict(feature_vector_list, omega_list)\n",
    "    error_list = price_list - prediction_list\n",
    "    loss = Get_Loss(error_list)\n",
    "    loss_history_list.append(loss)\n",
    "\n",
    "    for i in range(len(gradient_vector)):\n",
    "        for j in range(len(feature_vector_list)):\n",
    "            gradient_vector[i] += (-2) * error_list[j] * feature_vector_list[j][i]\n",
    "\n",
    "    gradient_array = np.array(gradient_vector)\n",
    "    gradient_array /= 2.0*len(feature_vector_list)\n",
    "    omega_list -= gradient_array * learning_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ed937a-205e-43ec-8054-eaa50a998888",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "## Cell 6:\n",
    "#### 简单的可视化操作\n",
    "#### 方便评估训练效率和拟合效果\n",
    "&nbsp;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e69eb2-8629-4484-a956-d68fbd7a58ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cell 6\n",
    "\n",
    "x_list = [i for i in range(100)]\n",
    "figure = plt.figure()\n",
    "subplot = figure.add_subplot()\n",
    "subplot.plot(x_list, loss_history_list,\n",
    "             marker='^', markersize=5,\n",
    "             markerfacecolor='orange', markeredgecolor='orange')\n",
    "\n",
    "subplot.set_title('Loss - Loop Count in Training Process')\n",
    "subplot.set_xlabel('Loop Count', fontsize=10)\n",
    "subplot.set_ylabel('Loss', fontsize=10)\n",
    "plt.show()\n",
    "\n",
    "figure = plt.figure()\n",
    "subplot = figure.add_subplot(projection='3d')\n",
    "subplot.plot(std_area_list, std_room_num_list, price_list,\n",
    "             marker='o', markersize=5,\n",
    "             markerfacecolor='brown', markeredgecolor='orange', linestyle='none')\n",
    "\n",
    "x = np.linspace(-4, 4, 80)\n",
    "y = np.linspace(-4, 4, 80)\n",
    "x, y = np.meshgrid(x, y)\n",
    "z = (omega_list[0] * x + omega_list[1] * y + omega_list[2])\n",
    "subplot.plot_surface(x, y, z)\n",
    "\n",
    "subplot.set_title('Get The Wonderful Plane')\n",
    "subplot.set_xlabel('STD Area', fontsize=10)\n",
    "subplot.set_ylabel('STD Room Number', fontsize=10)\n",
    "subplot.set_zlabel('(Price/1000)', fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aeaa9c0-3484-4e8d-b264-c26ccdaffb25",
   "metadata": {},
   "source": [
    "![此处应当通过markdown语法插入本地图片，显示loss-loop_count关系](./fig3.png)\n",
    "![此处应当通过markdown语法插入本地图片，显示对Train Set的拟合结果](./fig4.png)\n",
    "![此处应当通过markdown语法插入本地图片，显示对Train Set的拟合结果](./fig5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dafc0437-6441-410e-b32a-ebcfbb7ec6d2",
   "metadata": {},
   "source": [
    "## Cell 7:\n",
    "#### 完成对 Validation Set 的回归\n",
    "#### 注意这里认为 Validation Set 和 Train Set 的元素是独立同分布的关系\n",
    "#### 所以标准化操作时要复用先前求得的 Train Set 的均值和标准差\n",
    "#### 最后额外输出整个 Validation Set 的回归所得的loss值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771f9949-7b2c-4157-976e-7a6092fff4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7\n",
    "\n",
    "val_area_list = data_list_list[0][train_set_size: line_num]\n",
    "val_room_num_list = data_list_list[1][train_set_size: line_num]\n",
    "val_price_list = data_list_list[2][train_set_size: line_num]\n",
    "val_price_list /= 1000\n",
    "\n",
    "std_val_area_list = [(area - area_mean) / area_std_variance for area in val_area_list]\n",
    "std_val_room_num_list = [(room_num - room_num_mean) / room_num_std_variance for room_num in val_room_num_list]\n",
    "\n",
    "feature_vector_list = []\n",
    "for i in range(validation_set_size):\n",
    "    feature_vector_list.append([std_val_area_list[i], std_val_room_num_list[i], 1.0])\n",
    "\n",
    "prediction_list = Predict(feature_vector_list, omega_list)\n",
    "val_error_list = val_price_list - prediction_list\n",
    "loss = Get_Loss(val_error_list)\n",
    "\n",
    "figure = plt.figure()\n",
    "subplot = figure.add_subplot(projection='3d')\n",
    "subplot.plot(std_val_area_list, std_val_room_num_list, val_price_list,\n",
    "             marker='o', markersize=5,\n",
    "             markerfacecolor='brown', markeredgecolor='orange', linestyle='none')\n",
    "\n",
    "x = np.linspace(-4, 4, 80)\n",
    "y = np.linspace(-4, 4, 80)\n",
    "x, y = np.meshgrid(x, y)\n",
    "z = (omega_list[0] * x + omega_list[1] * y + omega_list[2])\n",
    "subplot.plot_surface(x, y, z)\n",
    "\n",
    "subplot.set_title('Validation')\n",
    "subplot.set_xlabel('STD Area', fontsize=10)\n",
    "subplot.set_ylabel('STD Room Number', fontsize=10)\n",
    "subplot.set_zlabel('(Price/1000)', fontsize=10)\n",
    "plt.show()\n",
    "\n",
    "print('Stabled Loss Value of Training Process: '+str(loss_history_list[99]))\n",
    "print('Loss Value of Validation Task: '+str(loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef74337-aeb5-4f85-90eb-49174d41c763",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Stabled Loss Value of Training Process: 2027.2547872027424\n",
    "#### Loss Value of Validation Task: 2646.5551344115825\n",
    "![此处应当通过markdown语法插入本地图片，显示对Validation Set的拟合结果](./fig6.png)\n",
    "&nbsp;\n",
    "# 好像还不错，试试加入正则化的步骤再来一次?\n",
    "&nbsp;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
